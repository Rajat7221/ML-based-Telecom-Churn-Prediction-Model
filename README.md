# ML-based-Telecom-Churn-Prediction-Model
# Telecom Churn Prediction üì°

## Project Overview üéØ

This project aims to develop a churn prediction model for a telecom company using a Kaggle dataset. The objective is to anticipate account churn and provide personalized offers to mitigate customer attrition. The model identifies potential churners within accounts, considering the impact of losing multiple customers per account, to enhance customer retention and minimize churn, thereby fostering long-term business sustainability and growth.

## Dataset Description üìä

### Variable Description
- **AccountID**: Account unique identifier
- **Churn**: Account churn flag (Target)
- **Tenure**: Tenure of account
- **City_Tier**: Tier of primary customer's city
- **CC_Contacted_L12m**: Number of times all the customers of the account contacted customer care in the last 12 months
- **Payment**: Preferred payment mode of the customers in the account
- **Gender**: Gender of the primary customer of the account
- **Service_Score**: Satisfaction score given by customers of the account on service provided by the company
- **Account_user_count**: Number of customers tagged with this account
- **Account_segment**: Account segmentation based on spend
- **CC_Agent_Score**: Satisfaction score given by customers of the account on customer care service provided by the company
- **Marital_Status**: Marital status of the primary customer of the account
- **Rev_per_month**: Monthly average revenue generated by the account in the last 12 months
- **Complain_l12m**: Any complaints raised by the account in the last 12 months
- **Rev_growth_yoy**: Revenue growth percentage of the account (last 12 months vs last 24 to 13 months)
- **Coupon_used_l12m**: Number of times customers used coupons for payment in the last 12 months
- **Day_Since_CC_connect**: Number of days since no customers in the account have contacted customer care
- **Cashback_l12m**: Monthly average cashback generated by the account in the last 12 months
- **Login_device**: Preferred login device of the customers in the account

### Data Types
- **Categorical Variables**: Churn, City_Tier, Payment, Gender, Account_segment, Marital_Status, Login_device
- **Numerical Variables**: Tenure, CC_Contacted_L12m, Service_Score, Account_user_count, CC_Agent_Score, Rev_per_month, Complain_l12m, Rev_growth_yoy, Coupon_used_l12m, Day_Since_CC_connect, Cashback_l12m

## Machine Learning Pipeline üöÄ

### 1. Exploratory Data Analysis (EDA) üîç
- Univariate analysis to understand the distribution of individual features.
- Bivariate analysis to explore relationships between pairs of variables.
- Multivariate analysis to uncover patterns and correlations involving multiple variables.

### 2. Data Cleaning / Preprocessing üßπ
- Handle missing values through imputation techniques (mean, median, or mode replacement).
- Remove duplicate records to ensure data integrity.
- Normalize or scale numerical features to bring them to a similar scale.
- Transform data types as necessary.

### 3. Choosing a Performance Metric üìè
- Select an appropriate metric to evaluate the performance of the churn prediction model.
- Common metrics include accuracy, precision, recall, F1-score, and AUC-ROC.
- Choose a metric that aligns with the business objective and reflects the importance of correctly predicting churn.

### 4. Model Building üõ†Ô∏è
- Implement various machine learning algorithms suitable for classification tasks (e.g., K-Nearest Neighbors, Logistic Regression, Random Forest, Gradient Boosting Machines).
- Tune hyperparameters using grid search or random search to optimize model performance.
- Train multiple models and compare their performance based on the chosen metric.

### 5. Model Validation ‚úÖ
- Split the dataset into training and testing sets to assess model generalization.
- Utilize cross-validation techniques such as k-fold cross-validation to ensure robustness of the model.
- Evaluate model performance on the testing set using the chosen performance metric.
- Validate the model's predictive power by assessing its ability to generalize to unseen data.

## Model Performance üìà

### Comparison of Various Models

#### Train Data
| Model                   | Accuracy | Precision | Recall | F1-score |
|-------------------------|----------|-----------|--------|----------|
| Decision Tree Classifier| 1.00     | 1.00      | 1.00   | 1.00     |
| KNN                     | 0.98     | 0.96      | 1.00   | 0.98     |
| Na√Øve Bayes             | 0.56     | 0.53      | 0.96   | 0.68     |
| ANN                     | 0.81     | 0.80      | 0.81   | 0.81     |
| LDA                     | 0.81     | 0.80      | 0.83   | 0.81     |
| Logistic Regression     | 0.81     | 0.81      | 0.83   | 0.82     |
| Random Forest           | 1.00     | 1.00      | 1.00   | 1.00     |

#### Test Data
| Model                   | Accuracy | Precision | Recall | F1-score |
|-------------------------|----------|-----------|--------|----------|
| Decision Tree Classifier| 0.96     | 0.95      | 0.96   | 0.96     |
| KNN                     | 0.96     | 0.94      | 1.00   | 0.97     |
| Na√Øve Bayes             | 0.56     | 0.53      | 0.96   | 0.68     |
| ANN                     | 0.81     | 0.80      | 0.81   | 0.81     |
| LDA                     | 0.81     | 0.80      | 0.84   | 0.82     |
| Logistic Regression     | 0.82     | 0.81      | 0.83   | 0.82     |
| Random Forest           | 0.99     | 0.98      | 0.99   | 0.99     |

### Best Model
Based on Accuracy and F1 Score (balance between precision and recall), the K-Nearest Neighbors (KNN) model is concluded to be the best-suited model. Random Forest (RF) and Decision Tree Classifier (DTC) are overfitted models. Na√Øve Bayes is underfitted and not considered.

### KNN Performance
- **Train Data**:
  - Score: 0.9807
  - AUC: 1.000
- **Test Data**:
  - Score: 0.9641
  - AUC: 0.995



